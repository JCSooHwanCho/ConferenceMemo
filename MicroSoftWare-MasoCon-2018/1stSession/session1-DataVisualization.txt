1st session - 올바른 데이터 시가고하와 탐색적 분석 도구를 찾아서

돈버는 시각화 - 대시보드 납품이나 인포그래픽 만들어 팔기 말고


비즈니스로 돈 버는 법
-우리 서비스/사업에 돈 낼법한 사람 찾아내기
-적절한 타이밍에 적절한 Offer를 적절한 I/F로 제공
-프로세스 개선
-잘버는 요인 찾아 더욱 강화
-새는 돈 막기

->사람, 시간의 흐름, Funnel(단계), 적절함(Right) -> Trial&error,Multi&cross Dimensional Slice & Dice, Hierachical Drill Down
=>이를 위해서 데이터 시각화가 중요하다!(단, 데이터가 충분히 많지 않으면 의미가 없다 - 페타 단위)

 모니터링
-데이터가 폭발적으로 증가할 때 필요 -> 대부분의 기업은 장애가 나서야 대응(Reactive)

성능 - 유저 입장에서는 응답 시간, 서버 입장에서는 시간당 명령어 처리량(TPS) -> 기준이 다르다

성능 지표 - 평균?(평균이 특이 데이터를 못 보게 할 수 있음->LogNormal Distribution)
        -백분위 단위?(역시 왜곡 가능)
        ->모든 데이터를 표현하는 분포방식을 사용(제니퍼 등)
        ->but 운영자를 위해서는 서버간의 관계를 중심으로 보여줘야 함
        ->한국은 운영자 파워가 쎄므로 운영자를 위한 모니터링 뷰가 필요

-올바른 가치 판단을 내릴 수 있는 표현, 니가 찾아봐라 X,누가 사느냐에 따라 뷰가 달라져야 함, 모든 걸 다 보여주면 사는 입장에서는 책임 문제 때문에 오히려 회피하려는 현상->적절히 왜곡해야...

블록체인 데이터를 시각화하기
-블록체인 : 데이터 빙하(?) 
    -> 데이터 품질이 의외로 좋다.(Transition형 데이터, 참여자들에 의해 검증된 데이터, Smart contract의 상태 데이터까지 다 있음->투명성)
    ->데이터 가져다쓰기는 힘들다(얼음 속 보석) - > 대부분 NoSQL형식, 원하는 데이터를 찾으려면 Linear Search가 필요

    그래서! 1. 블록을 일정 시간마다 가져와서 2. Parsing해서 좋은 곳(Fluentd->Elasticsearch, RDB, Hadoop을 이용한다) 3. 적절한 ETL과정을 거쳐서 시각화(현재는 kibana만으로 충분)

데이터 처리 단계
빅데이터 수집(데이터 수집/통합) - 360 고객 데이터 통합(데이터 정제/변환 - 개별 프로필 레벨 통합 관리)
- 빅데이터 분석/ 머신러닝 (세그멘테이션 - GUI기반 머신러닝 예측) - 개인화 자동실행(액티베이션)

Concern
1.고객은 데이터를 쉽게 주지 않는다. 무슨 데이터를 줘야하는지도 모른다. 심지어 예상한 대로 사용하지 않는다. -> 개발자들이 고민할 부분
2.너무 General하면 안 팔린다.뭐라 설명하기가 어려워서. -> 하나만 파거나, 레이어 하나를 얹어서 문제 해결을 할 수 있도록 만들어 주거나

*차트나 대시보드가 전부는 아니다. 다른 요소에 작더라도 시각적인 요소를 붙여서 엔지니어 이외의 사람도 사용할 수 있게 만드는 게 중요하다.(Task에 맞게 Optimization)

-플랫폼 관점에서의 주의사항
1.시각화 원천이 되는 데이터 고려 (저장된 데이터/실시간 데이터, 데이터 크기 및 종류 , 실시간 패치/배치, 가져올 때 변환/일단 가져온 뒤 변환)
2.시각화된 차트가 나오기까지의 전처리/분석 고려(전처리 복잡도/자동화 처리완료까지의 리드타임, 정형화된 템플릿으로 커버 안되는 Adhoc분석의 필요와 리드타임, 자유도와 정합성 동시 만족을 위한 데이터 모델링)
3.시각화 구현 자체(템플릿 다양성 및 Dimension 과 Measure의 디자인 자유도, 필터에 대한 고려, 모니터링 vs EDA(탐색적 시각화 분석))

플랫폼이고 뭐고 떠나서 주의사항
1.Metric(지표) 설계 - 진짜 도움 되요?
2.대시보드/차트 설계 누가 했어요? 설정된 거 쓴지 얼마나 되었나요?
3.대시보드 보면서 무슨 생각하고 있나요?
4.혼자 보고있나 같이보고 있나?
5.같이 보기만 하나? 이걸 근거로 뭔가 토론을 하나요?
6.정제를 위한 노가다에 투입한 시간과 구축된 시각화 플랫폼 갖고 노는 시간의 비율에 대해서는 어떻게 생각하나요?
-> 정제하는데 시간 오래 걸려서 애착 가진다는 사람이 의외로 많다.

-스타트업이 완전 시작단계이거나 유의미한 데이터가 없는 상황에서는 어떻게 하지?
    ->설문조사, 리서치 같은 거 하지말고
    ->무료버젼 솔루션으로도 괜찮은 것(amplitude 추천)으로 데이터를 모아야 한다.
    ->샘플링 X, 전체 데이터를 가지고 일할 생각을 해야 한다.
    
    *빅데이터 - 현재의 기술로 처리하기 어려울 정도의 규모의 데이터

-데이터 수집 패러다임의 변화 : 정제된 데이터 -> 실시간 리얼 데이터로 넘어가서 데이터를 못 다루면 더 이상 지식 기반 작업을 할 수없는 지경에 이름
    =>지식기반의 사업은 다 비슷한 상황. 도메인을 넘나드는 사업이 필요함.

-데이터 수집을 어떻게 해야하나? 모델링은? -> 조직의 상황과 역량에 따라 다르다. 역량 있는 사람이 있다면 처음부터 모델링을 잘 하면 되겠지만, 아니라면 지속적으로 리뷰를 거쳐서
정제할 수 밖에 없다. ->우리가 문제를 제대로 파악하고 있는가? 그 문제를 해결할 역량이 있는가? 